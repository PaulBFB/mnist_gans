{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Networks\n",
    "What are GANs? Generative Adversarial Networks consist of two artificial neural networks (sub-models) that compete in zero-sum game: a generator model and discriminator model. \n",
    "GANs are applicable broadly and used to, among other things, create photo-realistic images for visualization, to model motion patterns, to create 3D models of objects from 2D images and to process astronomical images. \n",
    "GANs are also used to naturally design user interaction with chatbots. GANs are also used in particle physics to accelerate time-consuming detector simulations.\n",
    "\n",
    "\n",
    "### To understand the difference and the interplay between the two sub-models, we first consider discriminative models.\n",
    "Discriminator models usually refers to modelling a classification problem, with the purpose to find a discriminant function that maps a given input onto a specific class.\n",
    "A classic example is spam detection: what is the probability that a given e-mail is spam (y) considering all words in that e-mail $(x) 🡪 p(y|x)$.\n",
    "\n",
    "\n",
    "This constitutes a supervised learning approach, that fundamentally aims to find the boundary between classes.\n",
    "Generative modelling on the other hand falls into the category of unsupervised learning within the machine learning domain, and aims to discover patterns \n",
    "within a given data set to then generate output that mimics the underlying data. \n",
    "\n",
    "Considering the spam detection example again, a generative approach would be as follows: \n",
    "- 1 assume a given e-mail in span; \n",
    "- 2 what is the probability of seeing these words (relevant for spam detection) in a particular e-mail.  Expressed in statistical terms, a generative approach models the joint probability of an observable variable and the target variable.\n",
    "\n",
    "Generally, a GAN architecture combines these two approaches where the generative model first creates (generates) new data from a vector of latent variables to the desired result space. \n",
    "\n",
    "The generator's aim is to learn to generate results based on a given data distribution to ultimately generate output that is indistinguishable from the ground truth. \n",
    "\n",
    "The discriminator, on the other hand is trained to distinguish the results of the generator from the (fake) data from the real data and labels the generators’ output accordingly. \n",
    "In this constellation, the discriminator provides feedback to the generator while simultaneously receiving feedback from the ground truth, the underlying data.\n",
    "\n",
    "![architecture_sketch](./img/GAN_architecture_diagram.png)\n",
    "\n",
    "The two models are organized such that they compete in a zero-sum game (a concept rooted in game theory, where gains and losses cancel each other out, resulting in zero), hence the term “adversarial”. \n",
    "\n",
    "For instance, the discriminator can be a convolutional network for binary classification, say images. \n",
    "The generator, in a sense, can be seen as an inverse convolutional network that takes random data to produce images. \n",
    "\n",
    "Both models aim to optimize their opposing loss function. The result is a natural (Nash) equilibrium, where the generator produces output that is classified as real 50% of times. \n",
    "\n",
    "Through this combination of models, a unsupervised learning approach is transformed to a supervised approach. The following analogy describes this area of tension.\n",
    "\n",
    ">_„We can think of the generator as being like a counterfeiter, trying to make fake money, and the discriminator as being like police, trying to allow legitimate money and catch counterfeit money. To succeed in this game, the counterfeiter must learn to make money that is indistinguishable from genuine money, and the generator network must learn to create samples that are drawn from the same distribution as the training data.“_\n",
    "\n",
    "![architecture_2](./img/architecture_diagram.png)\n",
    "\n",
    "## GAN Variations\n",
    "There exists a myriad GAN variations and evolutions as can be seen in the following table: \n",
    "\n",
    "![architecture_table](./img/architecture_table.png)\n",
    "\n",
    "However, a good starting point for image-synthesis-based is Deep Convolutional GANs (DCGAN), based on Radfort et al’s groundbreaking work, \n",
    "that condenses to five best practice points guideline points when designing an DCGAN:\n",
    "\n",
    "### Architecture guidelines for stable Deep Convolutional GANs\n",
    "\n",
    "- 1 Replace any pooling layers with strided convolutions (discriminator) and fractional-strided convolutions (generator). \n",
    "- 2 Use batchnorm in both the generator and the discriminator. \n",
    "- 3 Remove fully connected hidden layers for deeper architectures.\n",
    "- 4 Use ReLU activation in generator for all layers except for the output, which uses Tanh or sigmoid.\n",
    "- 5 Use LeakyReLU activation in the discriminator for all layers.\n",
    "\n",
    "\n",
    "The findings in this paper are earned hard, by scientific rigor and extensive testing.\n",
    "\n",
    "## Architecture Generator\n",
    "The authors suggest to replace _“…deterministic spatial pooling functions (such as maxpooling) with strided convolutions…“_ in order to allow the convolutional network its own spatial down sampling, \n",
    "as we have implemented in our MNIST-example. \n",
    "\n",
    "Furthermore, it is recommended to use flattened layers that are directly connected to the output layer (instead of fully connected layers) in the discriminator model, \n",
    "as this yield more model stability and leads to faster convergence. \n",
    "The first layer, then, could be seen as fully connected to the output layer Normalizing each input unit to have zero mean and variance (batch normalization) \n",
    "further stabilizes the learning process, since this supports gradient flow and initialization. \n",
    "\n",
    "Note, however, batch normalization should not be applied to the generator’s output layers and the discriminator’s input layers, due to arising problems of model fluctuations and instability.\n",
    "Further,  Radfort et al found that using ReLU activation results in faster learning rates in the domain of image classification, when used in the generator model \n",
    "(all layers except the output layer where Tanh function should be used). \n",
    "\n",
    "A leaky rectified activation should be used in the generator network.\n",
    "\n",
    "## Practical Implementation\n",
    "\n",
    "> For the complete code, see the [python script](./mnist_gan.py)\n",
    "\n",
    "We have implemented a small wrapper class to show a gan working with the well-documented [MNIST dataset](https://en.wikipedia.org/wiki/MNIST_database) of 70,000 small square 28×28 pixel grayscale images of handwritten single digits between 0 and 9. \n",
    "\n",
    "![examples](./img/mnist_sample.png)\n",
    "\n",
    "Our goal here is to create credible handwritten digits.\n",
    "\n",
    "As noted above, our model consists of a generator with the following architecture:\n",
    "\n",
    "![gen_architecture](./img/generator_architecture.png)\n",
    "\n",
    "Points to note:\n",
    "* as stated above we use leaky ReLu activation functions for activation\n",
    "* we create upsampling layers to scale our output from 7-14-28 pixels\n",
    "* as noted in point 1 of the architecture, we use fractional-strided convolutions\n",
    "\n",
    "Our discriminator has the following architecture:\n",
    "\n",
    "![discrimintaor_architecture](./img/discriminator_architecture.png)\n",
    "\n",
    "Again, this closely follows the recommendations by Radfort et al.\n",
    "\n",
    "Finally, these two Networks are connected sequentially and then trained together.\n",
    "\n",
    "### Important notes for the training of the network: \n",
    "\n",
    "Before training, we freeze the discriminant network, precluding it's weights from being updated, since we only want the generator network to converge more closely to the ground truth.\n",
    "\n",
    "Furthermore, as noted above, conceptually what happens in the interplay between generator and discriminator is that the generator tries to _\"deceive\"_ the discriminator, to facilitate this, the output of the generator is \"mislabeled\" as \"real\", which the generator will interpret as loss, causing it to converge.\n",
    "\n",
    "For the training process we initially used 100 epochs, the initial output of the generator was (as expected) pure noise:\n",
    "\n",
    "![initial_output](./img/initial_output.png)\n",
    "\n",
    "However, after the first 10 epochs, the generator's output already appeared to converge in the correct direction:\n",
    "\n",
    "![output_10_epochs](./img/output_10.png)\n",
    "\n",
    "After further epochs, the output (usually) converges quite closely to the ground truth, however we are running multiple rounds of training now to confirm in how many cases this does not occur.\n",
    "\n",
    "\n",
    "### Final Notes\n",
    "\n",
    "As we mentioned, the dynamic generator and the static discriminator are involved in a rather fragile zero-sum game here, and in some cases we noticed the loss of the discriminator sharply dropping down, which usually meant the generator has \"run astray\".\n",
    "\n",
    "This is why, in our current implementation, the model already saves checkpoints every 10 epochs, which enables us to pick the ideal model - any model checkpoint may be loaded using the keras load_model() function.\n",
    "\n",
    "The need to manually pick a model that generates the \"best\" handwritten digits is certainly a point yet to be addressed, nonetheless Generative Adversarial Networks are certainly a very promising and hence quickly expanding area. \n",
    "\n",
    "_____________________________________________________\n",
    "> Sources:\n",
    "Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks\n",
    "\n",
    ">NIPS 2016 Tutorial: Generative Adversarial Networks\n",
    "* https://en.wikipedia.org/wiki/Generative_model\n",
    "* https://www.freecodecamp.org/news/an-intuitive-introduction-to-generative-adversarial-networks-gans-7a2264a81394/\n",
    "* https://pathmind.com/wiki/generative-adversarial-network-gan\n",
    "* https://towardsdatascience.com/gan-objective-functions-gans-and-their-variations-ad77340bce3c-"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
